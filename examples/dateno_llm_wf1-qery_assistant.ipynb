{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvaoAI08+sCJCOn8cSHiPa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/sadov/f550f1053ca79b931038c33b1a40714c/dateno_llm_wf1-qery_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Первый этап workflow -- Query Assistant LLM-агент"
      ],
      "metadata": {
        "id": "elvHoQg3kcTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM-агент Query Assistant -- анализирует исходный запрос пользователя, определяет ключевые сущности, тему и контекст поиска. Формулирует уточняющие вопросы для устранения неоднозначности и сбора дополнительной информации. Переформулирует запрос в набор запросов для LLM-агента Dateno Search."
      ],
      "metadata": {
        "id": "X1eYvkNOk5iz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLPk6npBSToZ"
      },
      "outputs": [],
      "source": [
        "HF_TOKEN='YOUR DATENO HF SPACE TOKEN'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/datenoio/datenollm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLCmt3ybTHi0",
        "outputId": "789b2b8b-ff65-42d9-e06a-f42f687f4aec",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/datenoio/datenollm\n",
            "  Cloning https://github.com/datenoio/datenollm to /tmp/pip-req-build-g4h5l31r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/datenoio/datenollm /tmp/pip-req-build-g4h5l31r\n",
            "  Resolved https://github.com/datenoio/datenollm to commit be85bb7dc5af956df40e91c5806a1aeac8f67055\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.12/dist-packages (from datenollm==0.0.1) (1.11.1)\n",
            "Collecting logfire>=3.24.2 (from datenollm==0.0.1)\n",
            "  Downloading logfire-4.3.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting executing>=2.0.1 (from logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0 (from logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation>=0.41b0 (from logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-sdk<1.37.0,>=1.21.0 (from logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf>=4.23.4 in /usr/local/lib/python3.12/dist-packages (from logfire>=3.24.2->datenollm==0.0.1) (5.29.5)\n",
            "Requirement already satisfied: rich>=13.4.2 in /usr/local/lib/python3.12/dist-packages (from logfire>=3.24.2->datenollm==0.0.1) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from logfire>=3.24.2->datenollm==0.0.1) (4.14.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio_client->datenollm==0.0.1) (2025.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio_client->datenollm==0.0.1) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from gradio_client->datenollm==0.0.1) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio_client->datenollm==0.0.1) (25.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio_client->datenollm==0.0.1) (15.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio_client->datenollm==0.0.1) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio_client->datenollm==0.0.1) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio_client->datenollm==0.0.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio_client->datenollm==0.0.1) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio_client->datenollm==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (3.19.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (1.1.7)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0->logfire>=3.24.2->datenollm==0.0.1) (1.70.0)\n",
            "Collecting opentelemetry-api~=1.15 (from opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0->logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0->logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0->logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-instrumentation>=0.41b0->logfire>=3.24.2->datenollm==0.0.1)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-instrumentation>=0.41b0->logfire>=3.24.2->datenollm==0.0.1) (1.17.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0->logfire>=3.24.2->datenollm==0.0.1) (8.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.4.2->logfire>=3.24.2->datenollm==0.0.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.4.2->logfire>=3.24.2->datenollm==0.0.1) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->logfire>=3.24.2->datenollm==0.0.1) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client->datenollm==0.0.1) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.24.1->gradio_client->datenollm==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http<1.37.0,>=1.21.0->logfire>=3.24.2->datenollm==0.0.1) (3.23.0)\n",
            "Downloading logfire-4.3.3-py3-none-any.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.5/213.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl (32 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: datenollm\n",
            "  Building wheel for datenollm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datenollm: filename=datenollm-0.0.1-py3-none-any.whl size=26847 sha256=b350bea0bad86d2fa676c86d825e6e83c2e4dff71399d36f3be38b68c538f2f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dgav9bkf/wheels/e0/df/dd/8a6b3b355ce7d5a74ee77bb4f2ae23d95df4edbca4ca18871c\n",
            "Successfully built datenollm\n",
            "Installing collected packages: opentelemetry-proto, executing, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-http, logfire, datenollm\n",
            "Successfully installed datenollm-0.0.1 executing-2.2.0 logfire-4.3.3 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-http-1.36.0 opentelemetry-instrumentation-0.57b0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datenollm.client import DatenoClient\n",
        "from datenollm.jupiter_nb import ask_llm, QueryAssistantChatWidget, get_full_path, QueriesSelector"
      ],
      "metadata": {
        "id": "8-X73wX5IMb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стартуем клиент для доступа к HF Space, где работает нужный нам LLM-агент. М.б. придется позапускать несколько раз если будут ошибки -- HF Space засыпает если долго не использовался и запускается опять при обращении к нему. При таком раскладе -- заводиться может пинка с третьего."
      ],
      "metadata": {
        "id": "vwk1nE7mH898"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = DatenoClient('datenoio/explainable-query-assistant', hf_token=HF_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4SiftZDIkPq",
        "outputId": "096474d2-3f0b-47dd-e8d3-7b039712513b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://datenoio-explainable-query-assistant.hf.space ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим есть ли у нас доступ Google Disk'у. Если его нет, то последует запрос на выдачу разрешений для доступа к Google Account'у.\n",
        "\n",
        "Google запросит очень много разрешений. Однако, если выставить только разрешение на доступ к файлам и каталогам, то подключения к Google Disk не происходит.\n",
        "\n",
        "По умолчанию для сохранения в файлах истории и контекста мы используем только каталог /content/drive/MyDrive/colab_data/dateno/, ну или каталог указанный в переменной среды окружения `DRIVE_PATH`, ничего больше. См. https://github.com/datenoio/datenollm/blob/main/datenollm/file_utils.py\n",
        "\n",
        "Если условие предоставления доступа к данным на персональном Google Disk'е является критическим, можно порекомендовать запускать данный Google Collab notebook на другом аккаунте Google, где важных данных нет."
      ],
      "metadata": {
        "id": "o3A-2pfBqmIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEu94HDKqopE",
        "outputId": "eb3decb3-58e8-4cd0-d0fb-01fd21bcbaf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "После предоставления доступа проверяем есть ли каталог /content/drive/MyDrive/colab_data/dateno/, если нет -- он будет создан. Для чистоты эксперимента можно удалить файлы которые имеются в данном каталоге или перенести их в другой каталог."
      ],
      "metadata": {
        "id": "Bd9eb0KyuokB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_full_path('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "9DJL6wVbufGN",
        "outputId": "49b5030c-6453-4627-eff6-23d6fa808fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/colab_data/dateno/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты с LLM-агентом"
      ],
      "metadata": {
        "id": "9P3aSLv1rMtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяем гипотезу что специализированный Chain of Tought (CoT) из специального набора вопросов может быть эффективнее чем обычные запросы к LLM."
      ],
      "metadata": {
        "id": "peSYCazwsd4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первым делом надо сформулировать вопрос с которым будет работать LLM Query Assistant."
      ],
      "metadata": {
        "id": "bZMYUGlMvrRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Задайте вопрос:\n",
        "query = \"the trade turnover between Armenia and Cyprus\" # @param {\"type\":\"string\",\"placeholder\":\"Your query\"}\n",
        "\n",
        "if not query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "main_query = query"
      ],
      "metadata": {
        "id": "Tl3INkD7F8ru",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обычные запросы к LLM"
      ],
      "metadata": {
        "id": "wTK_tiUvl01X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут CoT не используем, а сразу отсылаем наш запрос в LLM.\n",
        "\n",
        "Историю будем писать в такой файл:"
      ],
      "metadata": {
        "id": "ghyuKTM5m41q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_file = \"history-eqa-llm.json\""
      ],
      "metadata": {
        "id": "Cq0w7ilhnAE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1-ый запрос отсылаем сразу в LLM\n",
        "\n",
        "if not main_query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "query, llm_response, history, error = ask_llm(client, main_query, history_file=history_file)\n",
        "rating_widget = QueryAssistantChatWidget(client, history_file)\n",
        "display(rating_widget.display())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427,
          "referenced_widgets": [
            "938fb833a1a448ac942589206ce6bc17",
            "83139965fa914d688766cc8ec74415ed",
            "a235e8a0c1934d9180a387966ad18475",
            "056f5e3eb7184490a499666e5774ec3a",
            "eed771809cbb41e989b2c7e753e9a015",
            "d20e25d589fe456fa34d69593fbd74b1",
            "16ba563ab73c41748da7e0ac17d9a12f",
            "9e840a077daf47d0949483f95e5bb956",
            "f0affa017dbe4039b8416140f19266ac",
            "90c91396bb684da294b4c57f30ca46aa",
            "139d3d17628d4b5cbab8abc8ea538258",
            "e04e38e0f76546758e74a104f61793fd",
            "bf93987f044f446fa63b34527c68028c",
            "a76a35de4784445a8d8fb9e56f4bf261",
            "352dbb3c95fc4fb8b93fde3ecbcd99d9",
            "99222633b34b48098d660ce67e1b7e0c"
          ]
        },
        "id": "YWktz7M2J8YN",
        "outputId": "cae51bb0-7850-491e-aaa0-3f62fc2bb7d2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_file='/content/drive/MyDrive/colab_data/dateno/history-eqa-llm.json'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='===============================================<br><strong>Query:</strong> <strong>…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "938fb833a1a448ac942589206ce6bc17"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ну и дальше общаемся с LLM как обычно\n",
        "query = \"for last 2 years\" # @param {\"type\":\"string\",\"placeholder\":\"Your query\"}\n",
        "\n",
        "if not query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "query, llm_response, history, error = ask_llm(client, query, history_file=history_file)\n",
        "rating_widget = QueryAssistantChatWidget(client, history_file)\n",
        "display(rating_widget.display())"
      ],
      "metadata": {
        "id": "_xo0ZOJ6KZyZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "0a4ff5bb1a304f70b5e84854ce69123f",
            "15549422a75443db8190d40f258abd2d",
            "16c452f9b6cf48bab47ae2d3ee904fd5",
            "a905c66092bd45cbbd33899f3464974d",
            "7d5b05e8f20d4c6984f4f7f595edd396",
            "6e6a644a097840f0b23945d1447f1443",
            "0ea3b6f72b7c4e80ae85c3dd9e1da53a",
            "673bae7ab3fd4c8c8767565cbac6c1c8",
            "a0fc4a4647394844b33cb141f99fb384",
            "bd4171c3f7704ea6b833cfe201b9cb40",
            "973687f7f0b84e069116245c749be02d",
            "3983103b6c63417ab88698e1eda6b85e",
            "2ff147fbeb864b3fb377478a5edfba3f",
            "a99047fff68246889af94dd61cc4ba76",
            "ad5c619e69284f828a51c5fff99e49c9",
            "13abd34a6d0d4729bbd1531fcefa6a01"
          ]
        },
        "cellView": "form",
        "outputId": "4da57314-7e88-4c30-a150-c139fbf0214b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_file='/content/drive/MyDrive/colab_data/dateno/history-eqa-llm.json'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='===============================================<br><strong>Question:</strong> <stro…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a4ff5bb1a304f70b5e84854ce69123f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запрос через Chain of Tought (CoT)"
      ],
      "metadata": {
        "id": "XkQn53sEq2ZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Историю для CoT пишем сюда:"
      ],
      "metadata": {
        "id": "VmxPRIWvmrjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_file = \"history-eqa-cot.json\""
      ],
      "metadata": {
        "id": "RmqOJZ_Tmoxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Отправить 1-ый CoT запрос к LLM:\n",
        "\n",
        "if not main_query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "llm_query = f\"\"\"\n",
        "I want to analyze the query:\n",
        "{main_query}\n",
        "\n",
        "As a professional economic analyst, tell me what methodological approaches are optimal for this?\n",
        "\"\"\"\n",
        "\n",
        "query, llm_response, history, error = ask_llm(client, llm_query, history_file=history_file)\n",
        "rating_widget = QueryAssistantChatWidget(client, history_file)\n",
        "display(rating_widget.display())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651,
          "referenced_widgets": [
            "29bd1ae3e16a4c92918178219a179bf8",
            "d64d4fd9eb1f49d7af7e28bce3c4c2ec",
            "ca9cb9ad527c4a3cad6cd128bcab8977",
            "4baf7844d9734d0cad597009db226f24",
            "34b7b4dc0e8d48bd97e788938c4bed53",
            "fa0794c8c3784bbe9edb9f55675b59fd",
            "5bfcd4eb04694488bb4bbe434c108c26",
            "aa27f7b335d54785b524f213110b4ea5",
            "3b3c31e5070b40cc9b85d90fb5a3d4c9",
            "b8d4d98bacb641ff969839dab0e7d8c4",
            "2945dc8e594a4b8ca8640c17e762fbce",
            "1cfeb95c33434482b0abf8b6642aa8bc",
            "8687ac40e8b340f5899e9240364b0f0f",
            "0f832731fd4045929575ef8c54e611ee",
            "21b64c78ca7f411697fa59b2fbc9d114",
            "546083f02b4a4e92b27dc1cd627b6203"
          ]
        },
        "id": "xPkhotyJFe7f",
        "outputId": "cdf27a8a-f565-41a4-f467-cd42cb1086f7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_file='/content/drive/MyDrive/colab_data/dateno/history-eqa-cot.json'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='===============================================<br><strong>Query:</strong> <strong>…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29bd1ae3e16a4c92918178219a179bf8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Отправить 2-ой CoT запрос к LLM\n",
        "\n",
        "if not main_query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "llm_query = f\"\"\"\n",
        "Divide these methods into those that require a high level of expertise and special knowledge, and those that are based directly on data analysis.\n",
        "\"\"\"\n",
        "\n",
        "query, llm_response, history, error = ask_llm(client, llm_query, history_file=history_file)\n",
        "rating_widget = QueryAssistantChatWidget(client, history_file)\n",
        "display(rating_widget.display())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "afce966648ac474aa8726098f506bb9d",
            "dae4c86cbf624753bbd9e143ca2a949e",
            "a2fa695f765a4e04a13c2fb571524d50",
            "0b58cd911baa4b549af7712d06c37532",
            "3bea5e61d1f6437da12ac5aeec53be93",
            "d305075f1c1c477cba7a0d71fb2d862f",
            "99700ddb27bc49ebae3037310331ffda",
            "45afbb6a58e040a3b21a8dfef4e36ae5",
            "e5d326eae6c24207a8c642fc101f266a",
            "4382926dc4a44d948fc57d7ae3529d3f",
            "3c7155a39b1f4b8589412e3a6e5e73d6",
            "0f8fef0fd85d4f1f9d1875783699fbeb",
            "06ba07de3e3041f195d4005723e0122b",
            "660fd02b113246589f2c15c44c4ba7c8",
            "67e254e925a34b4b8dca2ac95ae177e4",
            "5eb0ca57f4304c6481e3ae08488e3155"
          ]
        },
        "id": "xq-tdQKnH8WC",
        "outputId": "10af854b-fd0c-451c-a172-946d9289bae7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_file='/content/drive/MyDrive/colab_data/dateno/history-eqa-cot.json'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='===============================================<br><strong>Query:</strong> <strong>…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afce966648ac474aa8726098f506bb9d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Отправить 3-ий CoT запрос к LLM\n",
        "\n",
        "if not main_query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "llm_query = f\"\"\"\n",
        "For Data Analysis methods, list the required indicators and possible names of the corresponding data sets.\n",
        "\"\"\"\n",
        "\n",
        "query, llm_response, history, error = ask_llm(client, llm_query, history_file=history_file)\n",
        "rating_widget = QueryAssistantChatWidget(client, history_file)\n",
        "display(rating_widget.display())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "1f10ecb52ad44518b2ec9d774ca47263",
            "efe8c4c3f4df4e96a07baad0c0e05782",
            "96fdf2423d754f95a96af92f37b45b90",
            "ab0788456285479dab199d1b9fa822f8",
            "cbeec20c351b47d88ec4f88f5f41e27a",
            "8ace310fb9cd4ab4963d12dc083b1a15",
            "4c4412ff660b4b83b926bdff16e35b02",
            "ddf3756d4d654e48b7eaf506794d16be",
            "7aa2fde4a924413dac9ac825f108f028",
            "440ee90058394b9ba23c1c6f47e3d73c",
            "920a746849af4c1b892c33a9f18f506e",
            "c24a021797e04f4a91352eecdb0f86e3",
            "d16f99a32a964646a1c1417756d515f8",
            "a552542bb9b842b59f624626df83ba8c",
            "6053fcddd465413994e10e83024bfa57",
            "f97e1d996d23403fa6bc3390795c8998"
          ]
        },
        "id": "eUozYxUBIQFQ",
        "outputId": "83c9d770-ed7f-4a14-f11e-c12c6734c633",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_file='/content/drive/MyDrive/colab_data/dateno/history-eqa-cot.json'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='===============================================<br><strong>Query:</strong> <strong>…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f10ecb52ad44518b2ec9d774ca47263"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Ну и дальше общаемся с LLM как обычно:\n",
        "query = \"for last 2 years\" # @param {\"type\":\"string\",\"placeholder\":\"Your query\"}\n",
        "\n",
        "if not query:\n",
        "  raise ValueError('Query is empty')\n",
        "\n",
        "query, llm_response, history, error = ask_llm(client, query, history_file=history_file)\n",
        "rating_widget = QueryAssistantChatWidget(client, history_file)\n",
        "display(rating_widget.display())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455,
          "referenced_widgets": [
            "c77e7029b45641179ff6ccbfb799ce46",
            "55360d5407d24f998391137fb853a308",
            "3d1ebdb242be40cdab35543a7c18a9f4",
            "b2def47f3dda4d57ba4f9ea50d6f8e95",
            "63116ab3f2114171ad1715ae26ad39e4",
            "b5f54fd657e347aa86aff58f83f0dca8",
            "83ea43699f584dbfa5bdfe9fa89656d4",
            "900f860835414dd4b140c284301d9562",
            "7c5cac4efc4447478201ef22d0274d5b",
            "04d4c3ce3e8f4cc7aa6a1956b33cf742",
            "d584ff72fc334bfdbdb2a7d9b627cdb1",
            "53c89b5365034d75ae08580207b7f539",
            "f8d4e74435ec42889daf79a79037b7d3",
            "7be20fb383ca49b18b6d0e4b28ed53d7",
            "1fa531fd56d143c0a1593769de3245c7",
            "5d46296da4664b8a9db77a944953985d"
          ]
        },
        "id": "Y5xsUVNKIusc",
        "outputId": "8f09327b-8e83-416b-80fe-8236e946a539",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_file='/content/drive/MyDrive/colab_data/dateno/history-eqa-cot.json'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='===============================================<br><strong>Query:</strong> <strong>…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c77e7029b45641179ff6ccbfb799ce46"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выбор запросов для следующего этапа workflow"
      ],
      "metadata": {
        "id": "AKhOC8dupd6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут можем выбрать набор запросов который будет передан на следующий этап workflow. Список для выбора будет формироваться из того набора запросов который вы сформировали последним -- CoT или обычный запрос к LLM."
      ],
      "metadata": {
        "id": "FDPMl_MgspsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выберите запросы:\n",
        "llm_response = json.loads(llm_response)\n",
        "selector_widget = QueriesSelector(llm_response['queries'])\n",
        "display(selector_widget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346,
          "referenced_widgets": [
            "3172e84fb6184f2e852c6e46d5de7684",
            "18e9acc1b2a54d7a9ec4a405e7563cfa",
            "fb0b2a4919c24c9a96ffc505950d613d",
            "736cba2db7a04d97bb1b080c70d76fde",
            "820373ce25fa4524b9d88c9dac06b63c",
            "19dfbd7772794499b6c4778865686829",
            "7c6ecfdbd8bd4f338d6723bf17ce5b48",
            "8bef10d300ec42bc83ab6c168f637579",
            "bc51e0c5ba48400aaefede3350ca2f4d",
            "60c67d03d5c443f680691b7d8d252e00",
            "9e12e72b04ff46fe9131a57e50d45afe",
            "6c9aeecce04a4cdbb3a9040bb40e3549",
            "75464e13d9374990893bac305dcb38d1",
            "0d147c00cbdf4322aa69d0ce356ce28b",
            "3a7d0dec626d467f84bca3cf6275ffa9",
            "872dde55145d4be19714e64484b89af0",
            "a313d149db994f0c91f5e8e5ef3b8ddc",
            "cb5687bd8c9b44c9b9fcf6cd9c60e29b",
            "0c401c1b1973450a932d85a17d2fdb18",
            "4f83c67aa86b40888db7ca64558d2a02",
            "c0084bf557f14f04a9ff9f3cc50a563e",
            "7495567eff2f4c50b4d9e179b4f1056b",
            "ca6acc17541648a3870048f5f60718e3",
            "ed894da8779f445fbef102101d3011b7",
            "e01bab160ad44de0b9348f7baf4bbc81",
            "4850bde4bd504a4d8d3750b301a983bc",
            "55a719fb51ec47c3a3b9f0a15550de7b",
            "5569e9c9af3e40f78b245d253b286f9b"
          ]
        },
        "cellView": "form",
        "id": "ox2deAPs5D--",
        "outputId": "54bbc7d6-df02-414a-aadf-5df0c43c3521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "QueriesSelector(children=(Button(description='Select All', style=ButtonStyle()), Button(description='Select No…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3172e84fb6184f2e852c6e46d5de7684"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраняем выбранное в файле для передачи на следующий этап workflow:"
      ],
      "metadata": {
        "id": "TfCUFeqbp8Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selector_widget.save_selected_queries('workflow_step1.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbtYD0PeGU5m",
        "outputId": "acc2d936-a9a4-4965-8251-987446fdc337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected queries saved to workflow_step1.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Перейти к следующему разделу: [\"Второй этап workflow -- Dateno Search LLM-агент\"](https://gist.github.com/sadov/8d8954ee0635c491e9fcae25e27e1620#file-dateno_llm_wf2-dateno_search-ipynb)"
      ],
      "metadata": {
        "id": "nzbu6iNKnqt3"
      }
    }
  ]
}